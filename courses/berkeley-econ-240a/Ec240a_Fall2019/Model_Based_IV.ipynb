{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based instrumental variables estimation\n",
    "_Bryan Graham - University of California - Berkeley_  \n",
    "\n",
    "October 2019\n",
    "\n",
    "#### Code citation:\n",
    "<br>\n",
    "Graham, Bryan S. (2019). \"Model based instrumental variables estimation: Python Jupyter Notebook,\" (Version 1.0) [Computer program]. Available at http://bryangraham.github.io/econometrics/ (Accessed 19 March 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This notebook describes an implementation of a so called model based approach to the binary treatment, binary instrument, model described in, for example, Angrist, Imbens and Rubin (1996). Specifically it implements the parametric estimator proposed by Imbens and Rubin (1997). This is a maximum likelihood (MLE) estimator which recovers the potential outcome distribution, under both treatment and control, for the latent subpopulation of _compliers_ (units induced to change their treatment by the instrument). The potential outcome distributions, under control for _never takers_ , and under treatment for _always takers_ , are also recovered. The MLE is computed using the EM-Algorithm. Standard errors are constructed using either (i) a BFGS approximation to the (observed) log-likelihood Hessian matrix or (ii) a parametric bootstrap procedure. The latter method is recommended for empirical work.\n",
    "<br>\n",
    "<br>\n",
    "A textbook description of model-based instrumental variables analysis is provided by Imbens and Rubin (2015, Chapter 25). Relative to the the method-of-moments instrumental variables estimator, a model-based approach involves parametric modelling of potential outcome distributions across the various compliance strata. The trade-off here is greater efficiency at the cost of a potential lack of robustness to these extra distributional assumptions. Also relative to the method-of-moments approach, it is easier to incorporate additional covariates into a model-based analysis. In practice this can result in a much more flexible empirical analysis than is typical when using method-of-moments instrumental variables estimators. The implementation here assumes the potential outcome distributions are conditionally Gaussian given covariates and the latent compliance strata. Other distributional assumptions could be made.\n",
    "<br>\n",
    "<br>\n",
    "To illustrate the model based approach in practice, it is used to estimate the return to a 4-year college degree using the geographic proximity instrument of Card (1995). This analysis is not intended to be a replication analysis, nor a serious analysis of the returns to a college degree, it simply intended to provide a hands on illustration of model-based IV methods.\n",
    "<br>\n",
    "<br>\n",
    "**References**\n",
    "<br>\n",
    "<br>\n",
    "[1] Angrist, Joshua D., Guido W. Imbens and Donald B. Rubin. (1996). \"Identification of causal effects using instrumental variables,\" _Journal of the American Statistical Association_ 91 (434): 444 - 455\n",
    "<br>\n",
    "<br>\n",
    "[2] Card, David. (1995). \"Using geographic proximity to estimate the return to schooling,\" _Aspects of Labor Market Behavior: Essays in Honour of John Vanderkamp_ (L. N. Christofides, E. K. Grant and R. Swidinsky, Eds.).: 201 - 224. Toronto: University of Toronto Press.\n",
    "<br>\n",
    "<br>\n",
    "[3] Imbens, Guido W. and Donald B. Rubin. (1997). \"Estimating outcome distributions for compliers in instrumental variable models,\" _Review of Economic Studies_ 64 (4): 555 - 574.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I begin by loading a standard set of scientific computing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library dependencies\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import numpy.matlib\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('precision',4)\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the basic *ols* and *iv* commands available in my _ipt_ module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append location of ipt module base directory to system path\n",
    "# NOTE: only required if permanent install not made (see comments above)\n",
    "import sys\n",
    "sys.path.append('/Users/bgraham/Dropbox/Sites/software/ipt/')\n",
    "\n",
    "# import ols function from the ipt module\n",
    "from ipt import ols, iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Card (1995) dataset is available [online](http://davidcard.berkeley.edu/data_sets.html). This next block of code loads the dataset into memory and extracts an estimation sub-sample. This sub-sample is a subset of the one summarized in Column 3 of Table 1 in Card (1995, p. 203). Specially I additionally exclude black and southern respondents respondents as well as respondents with less than a high school degree. This leads to an estimation sample $ 1480 $ respondents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where supply-chain dataset source files are located\n",
    "data =  '/Users/bgraham/Dropbox/Teaching/Berkeley_Courses/Ec240a/Ec240a_Fall2019/ProblemSets/Card_RLE95_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nearc4</th>\n",
       "      <th>ed76</th>\n",
       "      <th>age76</th>\n",
       "      <th>daded</th>\n",
       "      <th>nodaded</th>\n",
       "      <th>momed</th>\n",
       "      <th>nomomed</th>\n",
       "      <th>weight</th>\n",
       "      <th>momdad14</th>\n",
       "      <th>...</th>\n",
       "      <th>reg663</th>\n",
       "      <th>reg664</th>\n",
       "      <th>reg665</th>\n",
       "      <th>reg666</th>\n",
       "      <th>reg667</th>\n",
       "      <th>reg668</th>\n",
       "      <th>south66</th>\n",
       "      <th>lwage76</th>\n",
       "      <th>black</th>\n",
       "      <th>smsa66r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>1480.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>483.4189</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>14.2608</td>\n",
       "      <td>28.1993</td>\n",
       "      <td>10.8973</td>\n",
       "      <td>0.1574</td>\n",
       "      <td>11.1894</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>385057.7514</td>\n",
       "      <td>0.8595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>307.4624</td>\n",
       "      <td>0.4221</td>\n",
       "      <td>2.1435</td>\n",
       "      <td>3.1492</td>\n",
       "      <td>2.7801</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0.2613</td>\n",
       "      <td>97957.7163</td>\n",
       "      <td>0.3477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4652</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>77455.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>199.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>9.9400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>358554.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>478.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>370732.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>765.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>418230.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>993271.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     nearc4       ed76      age76      daded    nodaded  \\\n",
       "count  1480.0000  1480.0000  1480.0000  1480.0000  1480.0000  1480.0000   \n",
       "mean    483.4189     0.7682    14.2608    28.1993    10.8973     0.1574   \n",
       "std     307.4624     0.4221     2.1435     3.1492     2.7801     0.3643   \n",
       "min       0.0000     0.0000    12.0000    24.0000     0.0000     0.0000   \n",
       "25%     199.7500     1.0000    12.0000    26.0000     9.9400     0.0000   \n",
       "50%     478.0000     1.0000    14.0000    28.0000    11.0000     0.0000   \n",
       "75%     765.0000     1.0000    16.0000    31.0000    12.0000     0.0000   \n",
       "max     999.0000     1.0000    18.0000    34.0000    18.0000     1.0000   \n",
       "\n",
       "           momed    nomomed       weight   momdad14  ...     reg663  \\\n",
       "count  1480.0000  1480.0000    1480.0000  1480.0000  ...  1480.0000   \n",
       "mean     11.1894     0.0736  385057.7514     0.8595  ...     0.3162   \n",
       "std       2.4900     0.2613   97957.7163     0.3477  ...     0.4652   \n",
       "min       0.0000     0.0000   77455.0000     0.0000  ...     0.0000   \n",
       "25%      10.0000     0.0000  358554.0000     1.0000  ...     0.0000   \n",
       "50%      12.0000     0.0000  370732.0000     1.0000  ...     0.0000   \n",
       "75%      12.0000     0.0000  418230.0000     1.0000  ...     1.0000   \n",
       "max      18.0000     1.0000  993271.0000     1.0000  ...     1.0000   \n",
       "\n",
       "          reg664  reg665  reg666  reg667     reg668  south66    lwage76  \\\n",
       "count  1480.0000  1480.0  1480.0  1480.0  1480.0000   1480.0  1480.0000   \n",
       "mean      0.1149     0.0     0.0     0.0     0.0534      0.0     6.3930   \n",
       "std       0.3190     0.0     0.0     0.0     0.2249      0.0     0.4141   \n",
       "min       0.0000     0.0     0.0     0.0     0.0000      0.0     4.7622   \n",
       "25%       0.0000     0.0     0.0     0.0     0.0000      0.0     6.1356   \n",
       "50%       0.0000     0.0     0.0     0.0     0.0000      0.0     6.4370   \n",
       "75%       0.0000     0.0     0.0     0.0     0.0000      0.0     6.6451   \n",
       "max       1.0000     0.0     0.0     0.0     1.0000      0.0     7.7849   \n",
       "\n",
       "        black    smsa66r  \n",
       "count  1480.0  1480.0000  \n",
       "mean      0.0     0.7358  \n",
       "std       0.0     0.4410  \n",
       "min       0.0     0.0000  \n",
       "25%       0.0     0.0000  \n",
       "50%       0.0     1.0000  \n",
       "75%       0.0     1.0000  \n",
       "max       0.0     1.0000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card = pd.read_fwf(data + 'nls.dat', na_values = '.', header=None)\n",
    "card = card[[0,2,5,7,8,9,10,11,12, 13,14,16,17,18,19,20,21,22,23,25,28,31,37]]\n",
    "card.rename(columns={0: \"id\", 2: \"nearc4\", 5: \"ed76\", \\\n",
    "                     7: \"age76\", 8: \"daded\", 9: \"nodaded\", 10: \"momed\", 11: \"nomomed\", \\\n",
    "                     12: \"weight\", 13: \"momdad14\", 14: \"sinmom14\", \\\n",
    "                     16: \"reg661\", 17: \"reg662\", 18: \"reg663\", 19: \"reg664\", \\\n",
    "                     20: \"reg665\", 21: \"reg666\", 22: \"reg667\", 23: \"reg668\", \\\n",
    "                     25: \"south66\", 28: \"lwage76\", 31: \"black\", 37: \"smsa66r\"}, inplace=True)\n",
    "card.dropna(how = 'any', inplace=True)\n",
    "card = card[(card.ed76 >= 12) & (card.black != 1) & (card.south66 != 1)]\n",
    "\n",
    "card.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>college</th>\n",
       "      <th>age76</th>\n",
       "      <th>smsa66r</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0000</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.3662</td>\n",
       "      <td>28.1993</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.4819</td>\n",
       "      <td>3.1492</td>\n",
       "      <td>0.4410</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         college      age76    smsa66r  constant\n",
       "count  1480.0000  1480.0000  1480.0000    1480.0\n",
       "mean      0.3662    28.1993     0.7358       1.0\n",
       "std       0.4819     3.1492     0.4410       0.0\n",
       "min       0.0000    24.0000     0.0000       1.0\n",
       "25%       0.0000    26.0000     0.0000       1.0\n",
       "50%       0.0000    28.0000     1.0000       1.0\n",
       "75%       1.0000    31.0000     1.0000       1.0\n",
       "max       1.0000    34.0000     1.0000       1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross sectional sampling weight\n",
    "sw = card['weight']\n",
    "\n",
    "# outcome: log wages in 1976\n",
    "Y = card['lwage76']\n",
    "\n",
    "# treatment: completed 4-year college degree\n",
    "D = (card['ed76']>=16)*1\n",
    "\n",
    "# instrument: lived near 4-year college\n",
    "Z = card['nearc4']\n",
    "\n",
    "# pre-treatment control variables\n",
    "X = card[['age76', 'smsa66r']]\n",
    "X = X.assign(constant=1)\n",
    "\n",
    "# combined instrument and controls\n",
    "ZX = X.copy(deep=True)\n",
    "ZX.insert(loc=0, column=\"nearc4\", value=Z)\n",
    "\n",
    "# combined treatment and controls\n",
    "DX = X.copy(deep=True)\n",
    "DX.insert(loc=0, column=\"college\", value=D)\n",
    "DX.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by computing the OLS fit of log wages onto the college dummy and pre-treatment controls. For this calculation, as well as all that follow, the NLS 1976 cross-sectional sampling weights are used. Compare these results with Table 2 of Card (1995, p. 206). To keep the analysis simple I only include the respondent's age and whether they resided in a standard metropolitan statistical area (SMSA) in 1966 as controls (college proximity covaries with this latter control). The estimated earnings premium associated with a college degree is just 9 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------\n",
      "-                     OLS ESTIMATION RESULTS                          -\n",
      "-----------------------------------------------------------------------\n",
      "Dependent variable:        lwage76\n",
      "Number of observations, n: 1480\n",
      "\n",
      "\n",
      "\n",
      "Independent variable       Coef.    ( Std. Err.)     (0.95 Confid. Interval )\n",
      "-------------------------------------------------------------------------------------------\n",
      "college                    0.090294 (  0.021156)     (  0.048829 ,  0.131760)\n",
      "age76                      0.048128 (  0.003313)     (  0.041633 ,  0.054622)\n",
      "smsa66r                    0.106975 (  0.022544)     (  0.062790 ,  0.151160)\n",
      "constant                   4.928739 (  0.094401)     (  4.743716 ,  5.113762)\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "NOTE: Heteroscedastic-robust standard errors reported\n",
      "NOTE: (Sampling) Weighted estimates computed.\n",
      "      Weight-variable   = weight\n"
     ]
    }
   ],
   "source": [
    "_ = ols(Y, DX, c_id=None, s_wgt=sw, nocons=True, silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I compute the first stage fit of college onto the proximity indicator and controls. Compare with Table 3 of Card (1995, p. 209). The results suggest that, on average, high school graduates residing near a four-year college were about 13 percentage points more likely to get a college degree. This effect is not precisely determined (the 95 percent confidence interval is from 0.06 to 0.19)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------\n",
      "-                     OLS ESTIMATION RESULTS                          -\n",
      "-----------------------------------------------------------------------\n",
      "Dependent variable:        ed76\n",
      "Number of observations, n: 1480\n",
      "\n",
      "\n",
      "\n",
      "Independent variable       Coef.    ( Std. Err.)     (0.95 Confid. Interval )\n",
      "-------------------------------------------------------------------------------------------\n",
      "nearc4                     0.126321 (  0.032697)     (  0.062236 ,  0.190406)\n",
      "age76                      0.008646 (  0.004096)     (  0.000618 ,  0.016675)\n",
      "smsa66r                   -0.043407 (  0.032453)     ( -0.107014 ,  0.020201)\n",
      "constant                   0.063506 (  0.117325)     ( -0.166446 ,  0.293459)\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "NOTE: Heteroscedastic-robust standard errors reported\n",
      "NOTE: (Sampling) Weighted estimates computed.\n",
      "      Weight-variable   = weight\n"
     ]
    }
   ],
   "source": [
    "_ = ols(D, ZX, c_id=None, s_wgt=sw, nocons=True, silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I compute the standard \"method-of-moments\" or linear IV estimate of the return to a college degree. Compare with Table 4 of Card (1995. p. 211). The estimated return is very imprecisely determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------\n",
      "-                    LINEAR IV/2SLS ESTIMATION RESULTS                -\n",
      "-----------------------------------------------------------------------\n",
      "Dependent variable:        lwage76\n",
      "Number of observations, n: 1480\n",
      "\n",
      "\n",
      "Independent variable       Coef.    ( Std. Err.)     (0.95 Confid. Interval )\n",
      "-------------------------------------------------------------------------------------------\n",
      "college                    0.116309 (  0.205476)     ( -0.286416 ,  0.519033)\n",
      "age76                      0.047883 (  0.003898)     (  0.040243 ,  0.055522)\n",
      "smsa66r                    0.106783 (  0.022550)     (  0.062586 ,  0.150980)\n",
      "constant                   4.926100 (  0.095855)     (  4.738228 ,  5.113972)\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "NOTE: Heteroscedastic-robust standard errors reported\n",
      "NOTE: (Sampling) Weighted estimates computed.\n",
      "      Weight-variable   = weight\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Endogenous right-hand-side regressors: \n",
      "-----------------------------------------------------------------------\n",
      "college                  \n",
      "\n",
      "Excluded instruments: \n",
      "-----------------------------------------------------------------------\n",
      "nearc4                   \n"
     ]
    }
   ],
   "source": [
    "_ = iv(Y, DX, ZX, c_id=None, s_wgt=sw, nocons=True, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LATE_mle(D, Y, X, Z, cLATE=False, nocons=True, s_wgt=None, silent=False, \\\n",
    "             theta_sv=None, gtol=1e-2, xtol=1e-4, maxiter=1000, skipHess=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    AUTHOR: Bryan S. Graham, UC - Berkeley, bgraham@econ.berkeley.edu\n",
    "    DATE: 8 Oct 2019    \n",
    "    \n",
    "    OVERVIEW\n",
    "    --------\n",
    "    \n",
    "    This function implements a model-based approach to Local Average\n",
    "    Treatement Effect estimation along the lines of Imbens and Rubin (1997, ReStud).\n",
    "    MLE mixture model methods are used; estimation proceeds using the EM-Algorithm. \n",
    "    An introduction to model-based methods of instrumental variable analysis is\n",
    "    provided by Imbens and Rubin (2015, Chapter 25). Users should start routine with\n",
    "    multiple sets of starting values to ensure that a global maximum of the mixture\n",
    "    log-likelihood has been found.\n",
    "        \n",
    "    INPUTS:\n",
    "    -------\n",
    "    D        : n X 1 pandas.Series of binary treatment\n",
    "    Y        : n X 1 pandas.Series of outcome variable\n",
    "    X        : n X K pandas.DataFrame of (functions of) pre-treatment control variables \n",
    "    Z        : n X 1 pandas.Series of binary instrument\n",
    "    cLATE    : If True impose E[Y(1) - Y(0)|X,A=c] equals a constant (i.e., no X interactions)  \n",
    "    nocons   : if True do not add a constant vector to X matrix of pre-treatment control variables\n",
    "               (if a constant is included program assumes that is in the last column of X) \n",
    "    s_wgt    : n X 1 pandas.Series of sampling weights  \n",
    "    silent   : if set equal to True, then suppress all estimation output \n",
    "    theta_sv : starting values for parameter vector (try alternatives in addition to default)\n",
    "    gtol     : optimization stopping criterion: change in logL\n",
    "    xtol     : optimization stopping criterion: norm of change in parameter values\n",
    "    maxiter  : optimization stopping criterion: maximum number of EM Algorithm steps\n",
    "    skipHess : If True then don't compute BFGS approximation of the inverse Hessian matrix.\n",
    "        \n",
    "    OUTPUTS:\n",
    "    --------\n",
    "    LATE_em            : Local average treatment effect estimate\n",
    "    strata_shares_em   : estimates of never-taker, complier and always-taker population shares\n",
    "    theta_em           : J x 1 vector of model parameter estimates\n",
    "    iH                 : J x J BFGS approximation of inverse Hessian matrix\n",
    "    converged          : True if EM algorithm appears to converge to a local max\n",
    "    \n",
    "    FUNCTIONS CALLED   : ...display_LATE_mle()...\n",
    "    ----------------      \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #-------------------------------------------------------#\n",
    "    #- First define a series of internal utility functions -#\n",
    "    #-------------------------------------------------------#\n",
    "    \n",
    "    def E_Step(theta, D, Y, Z, X, cLATE, sw):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function implements the E-Step of the EM-Algorithm. Specifically, given\n",
    "        the current parameter values it computes the responsibility of each compliance\n",
    "        strata for each sampled unit; these responsibilities can be used to construct\n",
    "        the observed (or integrated) log-likelihood.\n",
    "        \"\"\"\n",
    "        \n",
    "        # basic setup\n",
    "        K        = X.shape[1]                # number of control variables\n",
    "        theta    = np.reshape(theta,(-1,1))  # reshape parameter vector into 2d array\n",
    "        \n",
    "        # compliance strata (parameter subvectors)\n",
    "        gamma_c  = theta[0:K,0]              # multinomial logit coefficients for compliers\n",
    "        gamma_a  = theta[K:2*K,0]            # multinomial logit coefficients for always-takers\n",
    "        \n",
    "        # never-taker (parameter subvectors)\n",
    "        # Y(0)|X,A=n distribution parameters\n",
    "        beta_n0  = theta[2*K:3*K,0]          \n",
    "        sigma_n0 = theta[3*K,0]\n",
    "       \n",
    "        # complier & always-taker (parameter subvectors)\n",
    "        if cLATE:\n",
    "            #--------------------------------------------------------------------------#\n",
    "            # CASE 1: E[Y(1) - Y(0)|X,A=c] equals a constant. Reduces length of theta\n",
    "            #         by K-1 \n",
    "            #--------------------------------------------------------------------------#\n",
    "            \n",
    "            # complier (parameter subvector)\n",
    "            # Y(0)|X,A=c distribution parameters\n",
    "            beta_c0  = np.append(theta[(3*K+1):(4*K),0], theta[(4*K),0])\n",
    "            sigma_c0 = theta[(4*K+1),0]\n",
    "        \n",
    "            # Y(1)|X,A=c distribution parameters\n",
    "            # NOTE: slope coefficients in beta_c1 same as those in beta_c0 above (intercept different)\n",
    "            beta_c1  = np.append(theta[(3*K+1):(4*K),0], theta[(4*K+2),0])\n",
    "            sigma_c1 = theta[(4*K+3),0]\n",
    "\n",
    "            # always-taker (parameter subvector)\n",
    "            # Y(1)|X,A=a distribution parameters\n",
    "            beta_a1  = theta[(4*K+4):(5*K+4),0]  \n",
    "            sigma_a1 = theta[(5*K+4),0]\n",
    "        else:\n",
    "            #--------------------------------------------------------------------------#\n",
    "            # CASE 2: Complier Y(0) & Y(1) potential outcome distributions vary flexibly \n",
    "            #--------------------------------------------------------------------------#\n",
    "            \n",
    "            # complier (parameter subvector)\n",
    "            # Y(0)|X,A=c distribution parameters\n",
    "            beta_c0  = theta[(3*K+1):(4*K+1),0]  \n",
    "            sigma_c0 = theta[(4*K+1),0]\n",
    "        \n",
    "            # Y(1)|X,A=c distribution parameters\n",
    "            beta_c1  = theta[(4*K+2):(5*K+2),0]  \n",
    "            sigma_c1 = theta[(5*K+2),0]\n",
    "\n",
    "            # always-taker (parameter subvector)\n",
    "            # Y(1)|X,A=a distribution parameters\n",
    "            beta_a1  = theta[(5*K+3):(6*K+3),0]  \n",
    "            sigma_a1 = theta[(6*K+3),0]\n",
    "        \n",
    "        # never-taker (likelihood components)\n",
    "        p_n      = 1 / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))  \n",
    "        f_n0     = sp.stats.norm.pdf(Y, X @ beta_n0, sigma_n0)\n",
    "        \n",
    "        # complier (likelihood components)\n",
    "        p_c      = np.exp(X @ gamma_c) / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "        f_c0     = sp.stats.norm.pdf(Y, X @ beta_c0, sigma_c0)\n",
    "        f_c1     = sp.stats.norm.pdf(Y, X @ beta_c1, sigma_c1)\n",
    "        \n",
    "        # always-taker (likelihood components)\n",
    "        p_a      = np.exp(X @ gamma_a) / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "        f_a1     = sp.stats.norm.pdf(Y, X @ beta_a1, sigma_a1)\n",
    "        \n",
    "        # form strata responsibilities (save them as n x 1 2d numpy arrays, not Pandas Series )\n",
    "        t_n0     = ((1 - Z) * (1 - D) * (p_n * f_n0) / (p_n * f_n0 + p_c * f_c0) + Z * (1 - D)).values\n",
    "        t_c0     = ((1 - Z) * (1 - D) * (p_c * f_c0) / (p_n * f_n0 + p_c * f_c0)              ).values\n",
    "        t_c1     = (Z * D * (p_c * f_c1) / (p_c * f_c1 + p_a * f_a1)                          ).values\n",
    "        t_a1     = ((1 - Z) * D + Z * D * (p_a * f_a1) / (p_c * f_c1 + p_a * f_a1)            ).values\n",
    "    \n",
    "        # compute expected log-likelihood\n",
    "        E_LogL   = -np.sum(sw * (t_n0 * np.log(f_n0) + t_c0 * np.log(f_c0) + t_c1 * np.log(f_c1) + t_a1 * np.log(f_a1))) \\\n",
    "                   -np.sum(sw * (t_n0 * np.log(p_n)  + (t_c0 + t_c1) * np.log(p_c) + t_a1 * np.log(p_a)))\n",
    "    \n",
    "        # Return expected log-likelihood value and responsibility vectors (reshaped into n x 1 2d arrays)\n",
    "    \n",
    "        return [E_LogL, t_n0.reshape((-1,1)), t_c0.reshape((-1,1)), t_c1.reshape((-1,1)), t_a1.reshape((-1,1))]\n",
    "    \n",
    "    def E_LogL(theta, D, Y, Z, X, cLATE, sw):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function is used to numerically calculate the observed log-likelihood\n",
    "        Hessian. It is simply a clean call to E_Step()\n",
    "        \"\"\"\n",
    "        \n",
    "        elogl, _, _, _, _ = E_Step(theta, D, Y, Z, X, cLATE, sw)\n",
    "    \n",
    "        return elogl\n",
    "    \n",
    "    def strata_prob_E_LogL(gamma, t, X, sw):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function forms the portion of Q(theta,theta_current) function \n",
    "        associated with the multinomial logit model for the conditional \n",
    "        compliance strata probabilities. It is \"smoothed\" multinomial logit\n",
    "        log-likelihood (of sorts).\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get dimension of regressor vector and multinomial logit parameter values\n",
    "        K       = X.shape[1]                 \n",
    "        gamma_c = gamma[0:K].reshape((-1,1))\n",
    "        gamma_a = gamma[K:2*K].reshape((-1,1))\n",
    "        \n",
    "        # Get compliance strata responsibility vectors\n",
    "        t_n, t_c, t_a = t\n",
    "         \n",
    "        # Form conditional compliance strata probabilities and log-likelihood    \n",
    "        p_n      = 1                   / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "        p_c      = np.exp(X @ gamma_c) / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "        p_a      = np.exp(X @ gamma_a) / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "                \n",
    "        elogl   = -np.sum(sw * (t_n * np.log(p_n) + t_c * np.log(p_c) + t_a * np.log(p_a)))\n",
    "                \n",
    "        return elogl\n",
    "    \n",
    "    def strata_prob_E_Score(gamma, t, X, sw):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function forms the first derivative of Q(theta,theta_current) function \n",
    "        with respect to the parameters of the multinomial logit model for the conditional \n",
    "        compliance strata probabilities. It is the score vector of a \"smoothed\" \n",
    "        multinomial logit log-likelihood (of sorts).\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get dimension of regressor vector and multinomial logit parameter values\n",
    "        K       = X.shape[1]                \n",
    "        gamma_c = gamma[0:K].reshape((-1,1))\n",
    "        gamma_a = gamma[K:2*K].reshape((-1,1))\n",
    "        \n",
    "        # Get compliance strata responsibility vectors\n",
    "        t_n, t_c, t_a = t\n",
    "        \n",
    "        # Form conditional compliance strata probabilities\n",
    "        p_n      = 1                   / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "        p_c      = np.exp(X @ gamma_c) / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "        p_a      = np.exp(X @ gamma_a) / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "        \n",
    "        # form score vector and save as a 1d array\n",
    "        escore  = -np.vstack((np.sum(sw * (t_c - p_c) * X, axis = 0).T, np.sum(sw * (t_a - p_a) * X, axis = 0).T))\n",
    "        escore  = np.ravel(escore, order ='C') \n",
    "                \n",
    "        return escore\n",
    "            \n",
    "    def wls(Y, X, t, sw):\n",
    "        \n",
    "        \"\"\"\n",
    "        Computes the WLS fit of Y onto X given weights (sw * t). This function is used \n",
    "        to update the compliance-specific potential outcome distributions during \n",
    "        the M-Step of the EM Algorithm.\n",
    "        \"\"\"\n",
    "        \n",
    "        XX  = (sw * t * X).T @ X\n",
    "        XY  = (sw * t * X).T @ Y\n",
    "        beta_hat  = np.linalg.solve(XX, XY) \n",
    "        sigma_hat = np.average((Y - X @ beta_hat)**2, weights = np.ravel(sw * t))**(1/2)\n",
    "       \n",
    "        return [np.ravel(beta_hat), [sigma_hat]]\n",
    "    \n",
    "    #--------------------------------------------------------------------#\n",
    "    #- MAIN BODY OF FUNCTION                                            -#\n",
    "    #--------------------------------------------------------------------#\n",
    "    \n",
    "    #--------------------------------------------------------------------#\n",
    "    #- STEP 1 : Organize data                                           -#\n",
    "    #--------------------------------------------------------------------#\n",
    "    \n",
    "    n       = len(Y)                   # Number of observations\n",
    "    K       = X.shape[1]               # Number of control variables\n",
    "                    \n",
    "    # Extract controal variables from pandas data objects\n",
    "    con_var   = list(X.columns)        # Get control variable names\n",
    "    \n",
    "    # Add a constant to the control variable regressor matrix (if needed)\n",
    "    if not nocons:\n",
    "        X = X.assign(constant=1)\n",
    "        con_var.append(\"constant\")\n",
    "        K      += 1\n",
    "   \n",
    "    # Convert X to n x K 2d numpy array\n",
    "    X = X.values\n",
    "    \n",
    "    # Normalize weights to have mean one (if needed)\n",
    "    if s_wgt is None:\n",
    "        sw = np.ones((n,1)) \n",
    "    else:\n",
    "        s_wgt_var = s_wgt.name                               # Get sample weight variable name\n",
    "        sw = np.asarray(s_wgt/s_wgt.mean()).reshape((-1,1))  # Normalized sampling weights with mean one\n",
    "    \n",
    "    #--------------------------------------------------------------------#\n",
    "    #- STEP 2 : Get starting values                                     -#\n",
    "    #--------------------------------------------------------------------#\n",
    "    \n",
    "    # Initialize strata probability \"intercept\" parameters to match\n",
    "    # method-of-moments estimates of the fraction of compliers and\n",
    "    # always-takers in the population. Set all slope parameters to zero.\n",
    "    \n",
    "    p_c_sv = D[(Z == 1)].mean() - D[(Z == 0)].mean()\n",
    "    p_a_sv = D[(Z == 0)].mean()\n",
    "    \n",
    "    gamma_c0_sv, gamma_a0_sv = np.log(numpy.linalg.inv([[1-p_c_sv, -p_c_sv],[-p_a_sv, 1-p_a_sv]]) \\\n",
    "                                      @ [[p_c_sv], [p_a_sv]])\n",
    "    \n",
    "    gamma_c_sv  = np.append((K-1)*[0], gamma_c0_sv)\n",
    "    gamma_a_sv  = np.append((K-1)*[0], gamma_a0_sv)\n",
    "    gamma_sv    = np.concatenate((gamma_c_sv, gamma_a_sv))\n",
    "    \n",
    "    # Initialize Y(0) | X, A = n distribution parameters using Z = 1, D = 0 subsample\n",
    "    beta_n0_sv  = np.append((K-1)*[0], [Y[(Z == 1) & (D == 0)].mean()])\n",
    "    sigma_n0_sv = [Y[(Z == 1) & (D == 0)].std()]\n",
    "    \n",
    "    # Initialize Y(0) | X, A = c distribution parameters using Z = 0, D = 0 subsample\n",
    "    beta_c0_sv  = np.append((K-1)*[0], [Y[(Z == 0) & (D == 0)].mean()])\n",
    "    sigma_c0_sv = [Y[(Z == 0) & (D == 0)].std()]\n",
    "    \n",
    "    # Initialize Y(1) | X, A = c distribution parameters using Z = 1, D = 1 subsample\n",
    "    beta_c1_sv  = np.append((K-1)*[0], [Y[(Z == 1) & (D == 1)].mean()])\n",
    "    sigma_c1_sv = [Y[(Z == 1) & (D == 1)].std()]\n",
    "    \n",
    "    # Initialize Y(1) | X, A = a distribution parameters using Z = 0, D = 1 subsample\n",
    "    beta_a1_sv  = np.append((K-1)*[0], [Y[(Z == 0) & (D == 1)].mean()])\n",
    "    sigma_a1_sv = [Y[(Z == 0) & (D == 1)].std()]\n",
    "    \n",
    "    if cLATE:\n",
    "        #-----------------------------------------------------------------------------#\n",
    "        # CASE 1: E[Y(1) - Y(0)|X,A=c] equals a constant. Reduces length of theta_sv\n",
    "        #         by K-1 \n",
    "        #-----------------------------------------------------------------------------#\n",
    "        theta_sv    = np.concatenate([gamma_c_sv, gamma_a_sv, \\\n",
    "                                      beta_n0_sv, sigma_n0_sv, \\\n",
    "                                      (K-1)*[0], [beta_c0_sv[-1]], sigma_c0_sv, [beta_c1_sv[-1]], sigma_c1_sv, \\\n",
    "                                      beta_a1_sv, sigma_a1_sv])     \n",
    "    \n",
    "    else:\n",
    "        #-----------------------------------------------------------------------------#\n",
    "        # CASE 2: Complier Y(0) & Y(1) potential outcome distributions vary flexibly\n",
    "        #-----------------------------------------------------------------------------#\n",
    "        theta_sv    = np.concatenate([gamma_c_sv, gamma_a_sv, \\\n",
    "                                      beta_n0_sv, sigma_n0_sv, beta_c0_sv, sigma_c0_sv, \\\n",
    "                                      beta_c1_sv, sigma_c1_sv, beta_a1_sv, sigma_a1_sv]) \n",
    "    \n",
    "    #--------------------------------------------------------------------#\n",
    "    #- STEP 3 : EM - Algorithm                                          -#\n",
    "    #--------------------------------------------------------------------#\n",
    "    \n",
    "    finished = False\n",
    "    converged = False\n",
    "    logl_sv  = -np.inf\n",
    "    \n",
    "    iter = 0  # initialize iteration counter\n",
    "    \n",
    "    while not finished:\n",
    "        \n",
    "        # ----------------------------------------------------------------------#\n",
    "        # - E-Step: Compute latent strata responsibilities                     -#\n",
    "        # ----------------------------------------------------------------------#\n",
    "        \n",
    "        # Get current likelihood value and cluster responsibility vectors\n",
    "        logl, t_n0, t_c0, t_c1, t_a1 = E_Step(theta_sv, D, Y, Z, X, cLATE=cLATE, sw=sw)\n",
    "        t = [t_n0, t_c0+t_c1, t_a1]\n",
    "    \n",
    "        \n",
    "        # Print optimization output to screen\n",
    "        if (iter > 0) & (not silent):\n",
    "            print(\"Value of expected logL = \"       + \"%.6f\" % -logl + \\\n",
    "                  \",  2-norm of change in theta = \" + \"%.6f\" % delta)\n",
    "    \n",
    "        # Calculate likelihood increment and update likelihood value\n",
    "        Dlogl   = np.abs(logl - logl_sv)\n",
    "        logl_sv = logl\n",
    "        \n",
    "        # ----------------------------------------------------------------------#\n",
    "        # - M-Step: Update parameter values                                     #\n",
    "        # ----------------------------------------------------------------------#\n",
    "        \n",
    "        # (a) update multinomial logit coefficients for compliance strata membership model\n",
    "        options_set = {'xtol': xtol, 'maxiter': maxiter, 'disp': False}\n",
    "        gamma_em_res = sp.optimize.minimize(strata_prob_E_LogL, gamma_sv, args=(t, X, sw), \\\n",
    "                                            method='Newton-CG', jac = strata_prob_E_Score, \\\n",
    "                                            callback = None, options=options_set)\n",
    "        gamma_em = gamma_em_res.x\n",
    "        \n",
    "        \n",
    "        if cLATE:\n",
    "            #-----------------------------------------------------------------------------#\n",
    "            # CASE 1: E[Y(1) - Y(0)|X,A=c] equals a constant. Reduces length of theta_sv\n",
    "            #         by K-1 \n",
    "            #-----------------------------------------------------------------------------#\n",
    "            \n",
    "            # (b) update strata-specific potential outcome distribution estimates\n",
    "            # Never-taker and always-taker potential outcome distributions computed as in general\n",
    "            # case (CASE 2 below)\n",
    "            beta_n0_em, sigma_n0_em = wls(Y, X, t_n0, sw)\n",
    "            beta_a1_em, sigma_a1_em = wls(Y, X, t_a1, sw)\n",
    "            \n",
    "            # FGLS procedure to compute complier potential outcome distribution parameters\n",
    "            # under restriction that slope coefficients in Y(1)|X,A=c equal those in Y(0)|X,A=c\n",
    "            Ym = np.hstack((Y,Y))\n",
    "            Xm = np.hstack((np.vstack((np.ones((n,1)) , np.zeros((n,1)))), \\\n",
    "                            np.vstack((np.zeros((n,1)), np.ones((n,1)))), \\\n",
    "                            np.vstack((X[:,:-1],X[:,:-1]))))\n",
    "            \n",
    "            gls_converged = False\n",
    "            delta_c_sv =  np.concatenate([(K-1)*[0], [beta_c0_sv[-1]], sigma_c0_sv, [beta_c1_sv[-1]], sigma_c1_sv])\n",
    "            \n",
    "            while not gls_converged:\n",
    "                tm = np.vstack((t_c0/(delta_c_sv[K]**2),t_c1/(delta_c_sv[K+2]**2)))                        # FGLS weights\n",
    "                swm = np.vstack((sw,sw)) \n",
    "                beta_c_em, _ = wls(Ym, Xm, tm, swm)                                                        # Update coefs \n",
    "                beta_c0_em   = np.hstack((beta_c_em[2:], beta_c_em[0],))             \n",
    "                beta_c1_em   = np.hstack((beta_c_em[2:], beta_c_em[1]))\n",
    "                sigma_c0_em  = [np.average((Y - X @ beta_c0_em)**2, weights = np.ravel(sw * t_c0))**(1/2)] # Update FGLS \n",
    "                sigma_c1_em  = [np.average((Y - X @ beta_c1_em)**2, weights = np.ravel(sw * t_c1))**(1/2)] # weights\n",
    "                delta_c_em    = np.concatenate([beta_c_em[2:], \\\n",
    "                                               [beta_c_em[0]], sigma_c0_em, [beta_c_em[1]], sigma_c1_em])\n",
    "                # Assess parameter convergence \n",
    "                delta_gls = numpy.linalg.norm(delta_c_sv-delta_c_em)\n",
    "                delta_c_sv = delta_c_em\n",
    "                \n",
    "                # Stop when parameters converge\n",
    "                if (delta_gls < xtol):\n",
    "                    gls_converged = True\n",
    "        \n",
    "            \n",
    "            # (c) collected updated parameters\n",
    "            theta_em    = np.concatenate([gamma_em, \\\n",
    "                                          beta_n0_em, sigma_n0_em, \\\n",
    "                                          beta_c_em[2:], [beta_c_em[0]], sigma_c0_em, [beta_c_em[1]], sigma_c1_em, \\\n",
    "                                          beta_a1_em, sigma_a1_em])     \n",
    "    \n",
    "        else:\n",
    "            #-----------------------------------------------------------------------------#\n",
    "            # CASE 2: Complier Y(0) & Y(1) potential outcome distributions vary flexibly\n",
    "            #-----------------------------------------------------------------------------#\n",
    "            \n",
    "            # (b) update strata-specific potential outcome distribution estimates\n",
    "            beta_n0_em, sigma_n0_em = wls(Y, X, t_n0, sw)\n",
    "            beta_c0_em, sigma_c0_em = wls(Y, X, t_c0, sw)\n",
    "            beta_c1_em, sigma_c1_em = wls(Y, X, t_c1, sw)\n",
    "            beta_a1_em, sigma_a1_em = wls(Y, X, t_a1, sw)\n",
    "        \n",
    "            # (c) collected updated parameters\n",
    "            theta_em    = np.concatenate([gamma_em, \\\n",
    "                                      beta_n0_em, sigma_n0_em, beta_c0_em, sigma_c0_em, \\\n",
    "                                      beta_c1_em, sigma_c1_em, beta_a1_em, sigma_a1_em]) \n",
    "        \n",
    "        # Assess parameter convergence \n",
    "        delta = numpy.linalg.norm(theta_sv-theta_em)\n",
    "        \n",
    "        # Check if finished\n",
    "        if (Dlogl < gtol) | (delta < xtol) | (iter >= maxiter):\n",
    "            finished = True\n",
    "            if (Dlogl < gtol) | (delta < xtol):\n",
    "                converged = True\n",
    "        \n",
    "        # Update parameters\n",
    "        theta_sv = theta_em\n",
    "        iter += 1\n",
    "    \n",
    "    # compute MLEs of compliance strata shares\n",
    "    strata_shares_em = [np.mean(sw * t_n0), np.mean(sw * (t_c0+t_c1)), np.mean(sw * t_a1)]\n",
    "    \n",
    "    #--------------------------------------------------------------------#\n",
    "    #- STEP 4 : Compute variance-covariance matrix                      -#\n",
    "    #--------------------------------------------------------------------#\n",
    "    \n",
    "    if not skipHess:\n",
    "        if not silent:\n",
    "            print(\"\")\n",
    "            print(\"--------------------------------------------------------------\")\n",
    "            print(\"- Computing approximate inverse Hessian using BFGS algorithm -\")\n",
    "            print(\"--------------------------------------------------------------\")\n",
    "        # Using numerical estimate of log-likelihood Hessian for standard errors\n",
    "        # Use the BGFS algorithm to get approximation (which will be positive definite by construction)\n",
    "        options_set = {'gtol': gtol, 'maxiter': maxiter, 'disp': silent, 'norm': 10*delta}\n",
    "        opt_res = sp.optimize.minimize(E_LogL, theta_em, args=(D, Y, Z, X, cLATE, sw), \\\n",
    "                                       method='bfgs', jac = None, \\\n",
    "                                       callback = None, options=options_set)\n",
    "        if not opt_res.success:\n",
    "            print(\"\")\n",
    "            print(\"WARNING: BFGS approximation to inverse Hessian may be inaccurate.\")\n",
    "        iH = opt_res.hess_inv\n",
    "    else:\n",
    "        iH = np.NaN*np.ones((len(theta_em),len(theta_em)))\n",
    "    \n",
    "    #--------------------------------------------------------------------#\n",
    "    #- STEP 5 : Compute LATE                                            -#\n",
    "    #--------------------------------------------------------------------#\n",
    "    \n",
    "    if cLATE:\n",
    "        beta_c0_em = np.concatenate([theta_em[(3*K+1):(4*K)], [theta_em[4*K]]])\n",
    "        beta_c1_em = np.concatenate([theta_em[(3*K+1):(4*K)], [theta_em[4*K+2]]])\n",
    "        LATE_em = [np.average(X @ beta_c1_em - X @ beta_c0_em, weights = np.ravel(sw * (t_c0+t_c1)))]\n",
    "        var_LATE_em = (iH[4*K,4*K] + iH[4*K+1,4*K+1] - 2*iH[4*K,4*K+1])\n",
    "    else:\n",
    "        beta_c0_em = theta_em[(3*K+1):(4*K+1)]  \n",
    "        beta_c1_em = theta_em[(4*K+2):(5*K+2)]\n",
    "        LATE_em = [np.average(X @ beta_c1_em - X @ beta_c0_em, weights = np.ravel(sw * (t_c0+t_c1)))]\n",
    "        var_LATE_em = np.nan\n",
    "    \n",
    "    #--------------------------------------------------------------------#\n",
    "    #- STEP 6 : Display results if requested                            -#\n",
    "    #--------------------------------------------------------------------#\n",
    "    \n",
    "    if not silent:\n",
    "        display_LATE_mle(theta_em, iH, LATE_em, var_LATE_em, strata_shares_em, np.NaN*np.ones((3,3)), \\\n",
    "                         D, Y, Z, pd.DataFrame(X,columns=con_var), cLATE=cLATE, nocons=True)\n",
    "        print(\"\")  \n",
    "        print(\"Log-Likelihood,          logl : \" + \"{:<15,.1f}\".format(-logl))\n",
    "        \n",
    "        if s_wgt is not None:\n",
    "            print(\"NOTE: (Sampling) weighted MLEs computed.\")\n",
    "            print(\"      Weight-variable   = \" + s_wgt_var)    \n",
    " \n",
    "   \n",
    "    return [LATE_em, strata_shares_em, theta_em, iH, converged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_LATE_mle(theta, vcov_theta, LATE, var_LATE, strata_shares, vcov_strata_shares, \\\n",
    "                     D, Y, Z, X, cLATE=False, nocons=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function display estimation results produced by the LATE_mle() function.\n",
    "    See that functions documentation for details on parameters. Some of the above\n",
    "    parameters are generally computed as a by product of the parametric bootstrap\n",
    "    as implemented by the bsLATE_mle() function.\n",
    "    \"\"\"\n",
    "    \n",
    "    n       = len(Y)                   # Number of observations\n",
    "    K       = X.shape[1]               # Number of control variables\n",
    "                    \n",
    "    # Extract variable names from pandas data objects\n",
    "    out_var   = Y.name                 # Get outcome variable names\n",
    "    treat_var = D.name                 # Get treatment variable name\n",
    "    inst_var  = Z.name                 # Get instrumental variable name\n",
    "    con_var   = list(X.columns)        # Get control variable names\n",
    "    \n",
    "    # Add a constant to the control variable regressor matrix (if needed)\n",
    "    if not nocons:\n",
    "        X = X.assign(constant=1)\n",
    "        K += 1\n",
    "    \n",
    "    if cLATE:\n",
    "        #-----------------------------------------------------------------------------#\n",
    "        # CASE 1: E[Y(1) - Y(0)|X,A=c] equals a constant. Reduces length of theta_sv\n",
    "        #         by K-1\n",
    "        #-----------------------------------------------------------------------------#\n",
    "        \n",
    "        # compliance strata parameters\n",
    "        gamma_c  = theta[0:K]              # multinomial logit coefficients for compliers\n",
    "        stderr_gamma_c = np.diag(vcov_theta[0:K,0:K])**(1/2)\n",
    "    \n",
    "        gamma_a  = theta[K:2*K]            # multinomial logit coefficients for always-takers\n",
    "        stderr_gamma_a = np.diag(vcov_theta[K:2*K,K:2*K])**(1/2)\n",
    "    \n",
    "        # never-takers potential outcome parameters\n",
    "        # Y(0)|X,A=n distribution parameters\n",
    "        delta_n0 = theta[2*K:(3*K+1)]      \n",
    "        stderr_delta_n0 = np.diag(vcov_theta[2*K:(3*K+1),2*K:(3*K+1)])**(1/2)\n",
    "    \n",
    "        # compliers potential outcome parameters\n",
    "        # Y(0)|X,A=c distribution parameters\n",
    "        delta_c0 = np.concatenate([theta[(3*K+1):(4*K)], [theta[4*K]], [theta[4*K+1]]])\n",
    "        stderr_delta_c0 = np.concatenate([np.diag(vcov_theta[(3*K+1):(4*K),(3*K+1):(4*K)])**(1/2), \\\n",
    "                                         [vcov_theta[4*K,4*K]**(1/2)], [vcov_theta[4*K+1,4*K+1]**(1/2)]])\n",
    "        \n",
    "        # Y(1)|X,A=c distribution parameters\n",
    "        delta_c1 = np.concatenate([theta[(3*K+1):(4*K)], [theta[4*K+2]], [theta[4*K+3]]])\n",
    "        stderr_delta_c1 = np.concatenate([np.diag(vcov_theta[(3*K+1):(4*K),(3*K+1):(4*K)])**(1/2), \\\n",
    "                                         [vcov_theta[4*K+2,4*K+2]**(1/2)], [vcov_theta[4*K+3,4*K+3]**(1/2)]])\n",
    "    \n",
    "        # always-takers potential outcome parameters\n",
    "        delta_a1  = theta[(4*K+4):(5*K+5)] # Y(1)|X,A=a distribution parameters\n",
    "        stderr_delta_a1 = np.diag(vcov_theta[(4*K+4):(5*K+5),(4*K+4):(5*K+5)])**(1/2)\n",
    "        \n",
    "    else:\n",
    "        #-----------------------------------------------------------------------------#\n",
    "        # CASE 2: Complier Y(0) & Y(1) potential outcome distributions vary flexibly\n",
    "        #-----------------------------------------------------------------------------#\n",
    "        \n",
    "        # compliance strata parameters\n",
    "        gamma_c  = theta[0:K]              # multinomial logit coefficients for compliers\n",
    "        stderr_gamma_c = np.diag(vcov_theta[0:K,0:K])**(1/2)\n",
    "    \n",
    "        gamma_a  = theta[K:2*K]            # multinomial logit coefficients for always-takers\n",
    "        stderr_gamma_a = np.diag(vcov_theta[K:2*K,K:2*K])**(1/2)\n",
    "    \n",
    "        # never-takers potential outcome parameters\n",
    "        # Y(0)|X,A=n distribution parameters\n",
    "        delta_n0 = theta[2*K:(3*K+1)]      \n",
    "        stderr_delta_n0 = np.diag(vcov_theta[2*K:(3*K+1),2*K:(3*K+1)])**(1/2)\n",
    "    \n",
    "        # compliers potential outcome parameters\n",
    "        # Y(0)|X,A=c distribution parameters\n",
    "        delta_c0 = theta[(3*K+1):(4*K+2)]  \n",
    "        stderr_delta_c0 = np.diag(vcov_theta[(3*K+1):(4*K+2),(3*K+1):(4*K+2)])**(1/2)\n",
    "    \n",
    "        # Y(1)|X,A=c distribution parameters\n",
    "        delta_c1 = theta[(4*K+2):(5*K+3)]  \n",
    "        stderr_delta_c1 = np.diag(vcov_theta[(4*K+2):(5*K+3),(4*K+2):(5*K+3)])**(1/2)\n",
    "    \n",
    "        # always-takers potential outcome parameters\n",
    "        # Y(1)|X,A=a distribution parameters\n",
    "        delta_a1  = theta[(5*K+3):(6*K+4)] \n",
    "        stderr_delta_a1 = np.diag(vcov_theta[(5*K+3):(6*K+4),(5*K+3):(6*K+4)])**(1/2)\n",
    "\n",
    "    # Pandas dataframe of multinomial logit estimates of compliance strata model\n",
    "    strata_results = pd.DataFrame(np.vstack((gamma_c, stderr_gamma_c, gamma_a, stderr_gamma_a)).T, con_var, \\\n",
    "                                  ['compliers', 's.e.', 'always-takers', 's.e.'])\n",
    "    \n",
    "    # Pandas dataframe of compliance strata shares and standard errors\n",
    "    strata_share_results=pd.DataFrame({'share': strata_shares, 's.e.': np.diag(vcov_strata_shares)},\\\n",
    "                                      index=['never-takers','compliers','always-takers'])\n",
    "    \n",
    "    # Compute and collect potential outcome distribution parameter estimates into a Pandas dataframe\n",
    "    con_var.append(\"sigma\")\n",
    "    potential_outcome_results = pd.DataFrame(np.vstack((delta_n0, stderr_delta_n0, delta_c0, stderr_delta_c0, \\\n",
    "                                                        delta_c1, stderr_delta_c1, delta_a1, stderr_delta_a1)).T, \\\n",
    "                                             con_var, \\\n",
    "                                             ['Y(0): never-takers', 's.e.', 'Y(0): compliers', 's.e.', \\\n",
    "                                              'Y(1): compliers',    's.e.', 'Y(1): always-takers', 's.e.'])\n",
    "    \n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"- Model-based IV estimates                                                 -\")\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"Number of observations      n : \" + \"{:<15,.0f}\".format(n))\n",
    "    print(\"Outcome,                    Y : \" + out_var)\n",
    "    print(\"Treatment (binary),         D : \" + treat_var)\n",
    "    print(\"Instrument (binary),        Z : \" + inst_var)\n",
    "    print(\"(see results below for list of pre-treament control variables)\")\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"- Multinomial logit model for conditional compliance strata membership     -\")\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(strata_results)\n",
    "    print(\"\")\n",
    "    print(\"Estimated compliance strata population shares:\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(strata_share_results)\n",
    "    print(\"\")\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"- Gaussian models for potential outcome distributions                      -\")\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"\")\n",
    "    print(potential_outcome_results)\n",
    "    print(\"\")\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"- Model-based Local Average Treatement Effect Estimate                     -\")\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"LATE  :  \" + \"{:>10,.4f}\".format(LATE[0]))\n",
    "    print(\"s.e.  : (\" + \"{:>10,.4f}\".format(var_LATE**(1/2)) + \")\")\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsLATE_mle(theta_em, X, Z, cLATE=False, nocons=False, s_wgt=None, silent=False, B=100, gtol=1e-2, xtol=1e-4, maxiter=1000):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function implements a parametric boostrap procedure for the LATE_mle\n",
    "    command. See that function's documentation for more details on the\n",
    "    above parameters. The parametric bootstrap is the recommended method\n",
    "    for construction standard errors and confidence intervals.\n",
    "    \"\"\"\n",
    "    \n",
    "    #--------------------------------------------------------------------#\n",
    "    #- STEP 1 : Organize data & model parameters for simulation         -#\n",
    "    #--------------------------------------------------------------------#\n",
    "    \n",
    "    [n, K]    = X.shape                # Number of observations & control variables\n",
    "    con_var   = list(X.columns)        # Get control variable names\n",
    "    \n",
    "    # Add a constant to the control variable regressor matrix (if needed)\n",
    "    if not nocons:\n",
    "        X = X.assign(constant=1)\n",
    "        con_var.append(\"constant\")\n",
    "        K      += 1\n",
    "    \n",
    "    theta    = np.reshape(theta_em,(-1,1)) # reshape parameter into 2d array\n",
    "        \n",
    "    # compliance strata (parameter subvectors)\n",
    "    gamma_c  = theta[0:K,0]                # multinomial logit coefficients for compliers\n",
    "    gamma_a  = theta[K:2*K,0]              # multinomial logit coefficients for always-takers\n",
    "        \n",
    "    # never-taker (parameter subvectors)\n",
    "    # Y(0)|X,A=n distribution parameters\n",
    "    beta_n0  = theta[2*K:3*K,0]          \n",
    "    sigma_n0 = theta[3*K,0]\n",
    "       \n",
    "    # complier & always-taker (parameter subvectors)\n",
    "    if cLATE:\n",
    "        #--------------------------------------------------------------------------#\n",
    "        # CASE 1: E[Y(1) - Y(0)|X,A=c] equals a constant. Reduces length of theta\n",
    "        #         by K-1 \n",
    "        #--------------------------------------------------------------------------#\n",
    "            \n",
    "        # complier (parameter subvector)\n",
    "        # Y(0)|X,A=c distribution parameters\n",
    "        beta_c0  = np.append(theta[(3*K+1):(4*K),0], theta[(4*K),0])\n",
    "        sigma_c0 = theta[(4*K+1),0]\n",
    "        \n",
    "        # Y(1)|X,A=c distribution parameters\n",
    "        # NOTE: slope coefficients in beta_c1 same as those in beta_c0 above\n",
    "        beta_c1  = np.append(theta[(3*K+1):(4*K),0], theta[(4*K+2),0])\n",
    "        sigma_c1 = theta[(4*K+3),0]\n",
    "\n",
    "        # always-taker (parameter subvector)\n",
    "        # Y(1)|X,A=a distribution parameters\n",
    "        beta_a1  = theta[(4*K+4):(5*K+4),0]  \n",
    "        sigma_a1 = theta[(5*K+4),0]\n",
    "    else:\n",
    "        #--------------------------------------------------------------------------#\n",
    "        # CASE 2: Complier Y(0) & Y(1) potential outcome distributions vary flexibly \n",
    "        #--------------------------------------------------------------------------#\n",
    "            \n",
    "        # complier (parameter subvector)\n",
    "        # Y(0)|X,A=c distribution parameters\n",
    "        beta_c0  = theta[(3*K+1):(4*K+1),0]  \n",
    "        sigma_c0 = theta[(4*K+1),0]\n",
    "        \n",
    "        # Y(1)|X,A=c distribution parameters\n",
    "        beta_c1  = theta[(4*K+2):(5*K+2),0]  \n",
    "        sigma_c1 = theta[(5*K+2),0]\n",
    "\n",
    "        # always-taker (parameter subvector)\n",
    "        # Y(1)|X,A=a distribution parameters\n",
    "        beta_a1  = theta[(5*K+3):(6*K+3),0]  \n",
    "        sigma_a1 = theta[(6*K+3),0]\n",
    "    \n",
    "    # Compute compliance strata conditional probabilities\n",
    "    p_n      = 1 / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "    p_c      = np.exp(X @ gamma_c) / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "    p_a      = np.exp(X @ gamma_a) / (1+np.exp(X @ gamma_c) + np.exp(X @ gamma_a))\n",
    "    \n",
    "    # initialize matrix to store bootstrap results (LATE, compliance strata shares and theta)\n",
    "    Bootstrap_Results = [np.zeros((B,1)), np.zeros((B,3)), np.zeros((B,len(theta_em)))]\n",
    "    \n",
    "    for b in range(0,B):\n",
    "        start = time.time()\n",
    "        \n",
    "        # Simulate compliance types\n",
    "        U   = np.random.uniform(0,1,(n,))\n",
    "        A_n = 1*(U<=p_n)\n",
    "        A_c = 1*(U>p_n)*(U<=(p_n+p_c))\n",
    "        A_a = 1*(U>(p_n+p_c))\n",
    "        \n",
    "        # Reconstruct/simulate treatment choices based on simulated types\n",
    "        # NOTE: choice is deterministic given compliance type and instrument value\n",
    "        D = 0*A_n + Z*A_c + 1*A_a\n",
    "        \n",
    "        # Simulate outcomes based on types and treatments\n",
    "        Y0n = np.random.normal(X @ beta_n0, sigma_n0)\n",
    "        Y0c = np.random.normal(X @ beta_c0, sigma_c0)\n",
    "        Y1c = np.random.normal(X @ beta_c1, sigma_c1)\n",
    "        Y1a = np.random.normal(X @ beta_a1, sigma_a1)\n",
    "        Y   = Y0n*A_n + (1-D)*A_c*Y0c + D*A_c*Y1c + Y1a*A_a\n",
    "        \n",
    "        D = pd.Series(D, name=\"D\")\n",
    "        Y = pd.Series(Y, name=\"Y\")\n",
    "        \n",
    "        # Fit model to simulated data\n",
    "        [LATE_b, strata_shares_b, theta_b, _, _] = LATE_mle(D, Y, X, Z, cLATE=cLATE, nocons=True, s_wgt=s_wgt, \\\n",
    "                                                            silent=True, \\\n",
    "                                                            theta_sv=theta_em, gtol=gtol, xtol=xtol, \\\n",
    "                                                            maxiter=maxiter, skipHess=True)\n",
    "        \n",
    "        # Store results from bth bootstrap replication\n",
    "        Bootstrap_Results[0][b,:] = LATE_b\n",
    "        Bootstrap_Results[1][b,:] = strata_shares_b\n",
    "        Bootstrap_Results[2][b,:] = theta_b\n",
    "        \n",
    "        end = time.time()\n",
    "        if (b+1) % 1 == 0:\n",
    "            print(\"Time required f/ boostrap rep  \" + \\\n",
    "                  str(b+1) + \" of \" + str(B) + \": \" + str(end-start))   \n",
    "        \n",
    "        var_LATE = np.cov(Bootstrap_Results[0], rowvar=False)\n",
    "        vcov_strata_shares = np.cov(Bootstrap_Results[1], rowvar=False)\n",
    "        vcov_theta = np.cov(Bootstrap_Results[2], rowvar=False)\n",
    "        \n",
    "        \n",
    "    return [Bootstrap_Results, var_LATE, vcov_strata_shares, vcov_theta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide some categories of warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now fit the same model (albeit with additional parametric assumptions, but also more flexible covariate interactions) by maximum likelihood. The LATE point estimate is similar to the method of moments one. This is striking as the LATE is allowed to vary with pre-treatment covariates in this model. An attempt to compute standard errors using the BFGS approximation to the inverse Hessian was not successful. Below I implement a parametric bootstrap procedure in order to compute standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of expected logL = -2924641.414423,  2-norm of change in theta = 3.630936\n",
      "Value of expected logL = -2909333.396233,  2-norm of change in theta = 0.900183\n",
      "Value of expected logL = -2898662.273690,  2-norm of change in theta = 0.352486\n",
      "Value of expected logL = -2889710.961960,  2-norm of change in theta = 0.415899\n",
      "Value of expected logL = -2886047.856142,  2-norm of change in theta = 1.138297\n",
      "Value of expected logL = -2882690.918767,  2-norm of change in theta = 0.097940\n",
      "Value of expected logL = -2881080.379958,  2-norm of change in theta = 0.083616\n",
      "Value of expected logL = -2877457.694596,  2-norm of change in theta = 1.010942\n",
      "Value of expected logL = -2877647.387872,  2-norm of change in theta = 0.164236\n",
      "Value of expected logL = -2877848.805856,  2-norm of change in theta = 0.113498\n",
      "Value of expected logL = -2877744.514170,  2-norm of change in theta = 0.075852\n",
      "Value of expected logL = -2877108.507078,  2-norm of change in theta = 0.065785\n",
      "Value of expected logL = -2875593.380224,  2-norm of change in theta = 0.101683\n",
      "Value of expected logL = -2876188.276745,  2-norm of change in theta = 0.143800\n",
      "Value of expected logL = -2877058.983159,  2-norm of change in theta = 0.032646\n",
      "Value of expected logL = -2875512.876524,  2-norm of change in theta = 0.178055\n",
      "Value of expected logL = -2876130.237309,  2-norm of change in theta = 0.170276\n",
      "Value of expected logL = -2875156.947229,  2-norm of change in theta = 0.348077\n",
      "Value of expected logL = -2874244.820202,  2-norm of change in theta = 0.207182\n",
      "Value of expected logL = -2879610.549243,  2-norm of change in theta = 1.241860\n",
      "Value of expected logL = -2881244.672104,  2-norm of change in theta = 0.041416\n",
      "Value of expected logL = -2882307.756967,  2-norm of change in theta = 0.020782\n",
      "Value of expected logL = -2883177.667703,  2-norm of change in theta = 0.009458\n",
      "Value of expected logL = -2883938.104332,  2-norm of change in theta = 0.005835\n",
      "Value of expected logL = -2884629.623134,  2-norm of change in theta = 0.004061\n",
      "Value of expected logL = -2885268.269114,  2-norm of change in theta = 0.003180\n",
      "Value of expected logL = -2885861.004821,  2-norm of change in theta = 0.002760\n",
      "Value of expected logL = -2886411.610854,  2-norm of change in theta = 0.002521\n",
      "Value of expected logL = -2886922.796447,  2-norm of change in theta = 0.002335\n",
      "Value of expected logL = -2887396.922929,  2-norm of change in theta = 0.002161\n",
      "Value of expected logL = -2887836.230056,  2-norm of change in theta = 0.001993\n",
      "Value of expected logL = -2888242.891110,  2-norm of change in theta = 0.001835\n",
      "Value of expected logL = -2888619.014502,  2-norm of change in theta = 0.001689\n",
      "Value of expected logL = -2888966.632664,  2-norm of change in theta = 0.001557\n",
      "Value of expected logL = -2889287.691148,  2-norm of change in theta = 0.001438\n",
      "Value of expected logL = -2889584.041171,  2-norm of change in theta = 0.001332\n",
      "Value of expected logL = -2889857.435612,  2-norm of change in theta = 0.001236\n",
      "Value of expected logL = -2890109.527790,  2-norm of change in theta = 0.001149\n",
      "Value of expected logL = -2890341.872231,  2-norm of change in theta = 0.001070\n",
      "Value of expected logL = -2890555.926757,  2-norm of change in theta = 0.000997\n",
      "Value of expected logL = -2890753.055544,  2-norm of change in theta = 0.000930\n",
      "Value of expected logL = -2890934.532747,  2-norm of change in theta = 0.000867\n",
      "Value of expected logL = -2891101.546500,  2-norm of change in theta = 0.000808\n",
      "Value of expected logL = -2891255.203109,  2-norm of change in theta = 0.000752\n",
      "Value of expected logL = -2891396.531365,  2-norm of change in theta = 0.000700\n",
      "Value of expected logL = -2891526.486840,  2-norm of change in theta = 0.000651\n",
      "Value of expected logL = -2891645.956178,  2-norm of change in theta = 0.000605\n",
      "Value of expected logL = -2891755.761255,  2-norm of change in theta = 0.000562\n",
      "Value of expected logL = -2891856.663230,  2-norm of change in theta = 0.000521\n",
      "Value of expected logL = -2891949.366479,  2-norm of change in theta = 0.000483\n",
      "Value of expected logL = -2892034.522326,  2-norm of change in theta = 0.000447\n",
      "Value of expected logL = -2892112.732632,  2-norm of change in theta = 0.000414\n",
      "Value of expected logL = -2892184.553198,  2-norm of change in theta = 0.000383\n",
      "Value of expected logL = -2892250.496996,  2-norm of change in theta = 0.000353\n",
      "Value of expected logL = -2892311.037216,  2-norm of change in theta = 0.000326\n",
      "Value of expected logL = -2892366.610127,  2-norm of change in theta = 0.000301\n",
      "Value of expected logL = -2892417.617778,  2-norm of change in theta = 0.000278\n",
      "Value of expected logL = -2892464.430536,  2-norm of change in theta = 0.000256\n",
      "Value of expected logL = -2892507.389444,  2-norm of change in theta = 0.000236\n",
      "Value of expected logL = -2892546.808429,  2-norm of change in theta = 0.000217\n",
      "Value of expected logL = -2892582.976357,  2-norm of change in theta = 0.000200\n",
      "Value of expected logL = -2892616.158970,  2-norm of change in theta = 0.000184\n",
      "Value of expected logL = -2892646.600659,  2-norm of change in theta = 0.000169\n",
      "Value of expected logL = -2892674.526118,  2-norm of change in theta = 0.000156\n",
      "Value of expected logL = -2892700.141889,  2-norm of change in theta = 0.000143\n",
      "Value of expected logL = -2892723.637788,  2-norm of change in theta = 0.000132\n",
      "Value of expected logL = -2892745.188219,  2-norm of change in theta = 0.000121\n",
      "Value of expected logL = -2892764.953398,  2-norm of change in theta = 0.000111\n",
      "Value of expected logL = -2892783.080478,  2-norm of change in theta = 0.000102\n",
      "\n",
      "--------------------------------------------------------------\n",
      "- Computing approximate inverse Hessian using BFGS algorithm -\n",
      "--------------------------------------------------------------\n",
      "\n",
      "WARNING: BFGS approximation to inverse Hessian may be inaccurate.\n",
      "----------------------------------------------------------------------------\n",
      "- Model-based IV estimates                                                 -\n",
      "----------------------------------------------------------------------------\n",
      "Number of observations      n : 1,480          \n",
      "Outcome,                    Y : lwage76\n",
      "Treatment (binary),         D : ed76\n",
      "Instrument (binary),        Z : nearc4\n",
      "(see results below for list of pre-treament control variables)\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "- Multinomial logit model for conditional compliance strata membership     -\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "          compliers  s.e.  always-takers  s.e.\n",
      "age76        0.0098   1.0         0.0090   1.0\n",
      "smsa66r      0.1248   1.0        -0.3526   1.0\n",
      "constant    -1.7815   1.0        -0.8213   1.0\n",
      "\n",
      "Estimated compliance strata population shares:\n",
      "----------------------------------------------\n",
      "\n",
      "                share  s.e.\n",
      "never-takers   0.5959   NaN\n",
      "compliers      0.1444   NaN\n",
      "always-takers  0.2597   NaN\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "- Gaussian models for potential outcome distributions                      -\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "          Y(0): never-takers  s.e.  Y(0): compliers  s.e.  Y(1): compliers  \\\n",
      "age76                 0.0403   1.0          -0.0061   1.0           0.0893   \n",
      "smsa66r               0.1142   1.0           0.2945   1.0          -0.3336   \n",
      "constant              5.1523   1.0           6.2152   1.0           4.0685   \n",
      "sigma                 0.3604   1.0           0.4904   1.0           0.4561   \n",
      "\n",
      "          s.e.  Y(1): always-takers  s.e.  \n",
      "age76      1.0               0.0568   1.0  \n",
      "smsa66r    1.0               0.1970   1.0  \n",
      "constant   1.0               4.7774   1.0  \n",
      "sigma      1.0               0.2981   1.0  \n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "- Model-based Local Average Treatement Effect Estimate                     -\n",
      "----------------------------------------------------------------------------\n",
      "LATE  :      0.0888\n",
      "s.e.  : (       nan)\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Log-Likelihood,          logl : -2,892,783.1   \n",
      "NOTE: (Sampling) weighted MLEs computed.\n",
      "      Weight-variable   = weight\n"
     ]
    }
   ],
   "source": [
    "LATE_em, strata_shares_em, theta_em, iH, converged = LATE_mle(D, Y, X, Z, cLATE=False, nocons=True, s_wgt=sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I use the parametric bootstrap to estimate standard errors for the LATE maximum likelihood estimates. I use 100 bootstrap replications. Since the EM Algorithm can be slow to converge, the bootstrap can be computationally intensive even for modest size datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required f/ boostrap rep  1 of 100: 3.8735570907592773\n",
      "Time required f/ boostrap rep  2 of 100: 1.6632046699523926\n",
      "Time required f/ boostrap rep  3 of 100: 4.126051902770996\n",
      "Time required f/ boostrap rep  4 of 100: 4.6180901527404785\n",
      "Time required f/ boostrap rep  5 of 100: 4.377985000610352\n",
      "Time required f/ boostrap rep  6 of 100: 3.4339520931243896\n",
      "Time required f/ boostrap rep  7 of 100: 4.236380100250244\n",
      "Time required f/ boostrap rep  8 of 100: 3.736760139465332\n",
      "Time required f/ boostrap rep  9 of 100: 2.176785945892334\n",
      "Time required f/ boostrap rep  10 of 100: 0.592965841293335\n",
      "Time required f/ boostrap rep  11 of 100: 39.25439476966858\n",
      "Time required f/ boostrap rep  12 of 100: 2.6712071895599365\n",
      "Time required f/ boostrap rep  13 of 100: 2.902730941772461\n",
      "Time required f/ boostrap rep  14 of 100: 32.32994198799133\n",
      "Time required f/ boostrap rep  15 of 100: 3.484834909439087\n",
      "Time required f/ boostrap rep  16 of 100: 46.53768491744995\n",
      "Time required f/ boostrap rep  17 of 100: 2.854468822479248\n",
      "Time required f/ boostrap rep  18 of 100: 2.6143710613250732\n",
      "Time required f/ boostrap rep  19 of 100: 4.150547981262207\n",
      "Time required f/ boostrap rep  20 of 100: 3.1296446323394775\n",
      "Time required f/ boostrap rep  21 of 100: 5.32440710067749\n",
      "Time required f/ boostrap rep  22 of 100: 46.40929913520813\n",
      "Time required f/ boostrap rep  23 of 100: 59.36915993690491\n",
      "Time required f/ boostrap rep  24 of 100: 3.9060139656066895\n",
      "Time required f/ boostrap rep  25 of 100: 48.46383881568909\n",
      "Time required f/ boostrap rep  26 of 100: 49.79930377006531\n",
      "Time required f/ boostrap rep  27 of 100: 70.99130916595459\n",
      "Time required f/ boostrap rep  28 of 100: 2.439962148666382\n",
      "Time required f/ boostrap rep  29 of 100: 3.2591569423675537\n",
      "Time required f/ boostrap rep  30 of 100: 56.5746910572052\n",
      "Time required f/ boostrap rep  31 of 100: 100.32588386535645\n",
      "Time required f/ boostrap rep  32 of 100: 67.07440733909607\n",
      "Time required f/ boostrap rep  33 of 100: 57.82248902320862\n",
      "Time required f/ boostrap rep  34 of 100: 3.583811044692993\n",
      "Time required f/ boostrap rep  35 of 100: 42.32640290260315\n",
      "Time required f/ boostrap rep  36 of 100: 38.18021297454834\n",
      "Time required f/ boostrap rep  37 of 100: 40.80161118507385\n",
      "Time required f/ boostrap rep  38 of 100: 4.649609088897705\n",
      "Time required f/ boostrap rep  39 of 100: 54.19039011001587\n",
      "Time required f/ boostrap rep  40 of 100: 3.0281379222869873\n",
      "Time required f/ boostrap rep  41 of 100: 68.26293206214905\n",
      "Time required f/ boostrap rep  42 of 100: 8.763264894485474\n",
      "Time required f/ boostrap rep  43 of 100: 41.4674232006073\n",
      "Time required f/ boostrap rep  44 of 100: 77.43973112106323\n",
      "Time required f/ boostrap rep  45 of 100: 66.50732707977295\n",
      "Time required f/ boostrap rep  46 of 100: 97.36694693565369\n",
      "Time required f/ boostrap rep  47 of 100: 97.08490490913391\n",
      "Time required f/ boostrap rep  48 of 100: 2.1249840259552\n",
      "Time required f/ boostrap rep  49 of 100: 2.7780160903930664\n",
      "Time required f/ boostrap rep  50 of 100: 7.354789733886719\n",
      "Time required f/ boostrap rep  51 of 100: 69.52665114402771\n",
      "Time required f/ boostrap rep  52 of 100: 16.271799087524414\n",
      "Time required f/ boostrap rep  53 of 100: 85.13111877441406\n",
      "Time required f/ boostrap rep  54 of 100: 8.015307903289795\n",
      "Time required f/ boostrap rep  55 of 100: 83.94663190841675\n",
      "Time required f/ boostrap rep  56 of 100: 12.372135877609253\n",
      "Time required f/ boostrap rep  57 of 100: 2.8424510955810547\n",
      "Time required f/ boostrap rep  58 of 100: 4.797770977020264\n",
      "Time required f/ boostrap rep  59 of 100: 2.9337668418884277\n",
      "Time required f/ boostrap rep  60 of 100: 4.467130899429321\n",
      "Time required f/ boostrap rep  61 of 100: 1.1480889320373535\n",
      "Time required f/ boostrap rep  62 of 100: 60.460769176483154\n",
      "Time required f/ boostrap rep  63 of 100: 9.24161410331726\n",
      "Time required f/ boostrap rep  64 of 100: 55.83836603164673\n",
      "Time required f/ boostrap rep  65 of 100: 10.146841049194336\n",
      "Time required f/ boostrap rep  66 of 100: 18.275105953216553\n",
      "Time required f/ boostrap rep  67 of 100: 41.13545608520508\n",
      "Time required f/ boostrap rep  68 of 100: 4.865692853927612\n",
      "Time required f/ boostrap rep  69 of 100: 1.4041929244995117\n",
      "Time required f/ boostrap rep  70 of 100: 3.2567570209503174\n",
      "Time required f/ boostrap rep  71 of 100: 2.4278829097747803\n",
      "Time required f/ boostrap rep  72 of 100: 4.040778160095215\n",
      "Time required f/ boostrap rep  73 of 100: 41.012473821640015\n",
      "Time required f/ boostrap rep  74 of 100: 2.5463390350341797\n",
      "Time required f/ boostrap rep  75 of 100: 6.3829052448272705\n",
      "Time required f/ boostrap rep  76 of 100: 3.9276809692382812\n",
      "Time required f/ boostrap rep  77 of 100: 6.096444845199585\n",
      "Time required f/ boostrap rep  78 of 100: 74.78275799751282\n",
      "Time required f/ boostrap rep  79 of 100: 51.87923002243042\n",
      "Time required f/ boostrap rep  80 of 100: 1.6253571510314941\n",
      "Time required f/ boostrap rep  81 of 100: 16.282133102416992\n",
      "Time required f/ boostrap rep  82 of 100: 5.960000038146973\n",
      "Time required f/ boostrap rep  83 of 100: 7.563003778457642\n",
      "Time required f/ boostrap rep  84 of 100: 62.178056955337524\n",
      "Time required f/ boostrap rep  85 of 100: 9.26655101776123\n",
      "Time required f/ boostrap rep  86 of 100: 2.8829500675201416\n",
      "Time required f/ boostrap rep  87 of 100: 3.388014078140259\n",
      "Time required f/ boostrap rep  88 of 100: 55.58399510383606\n",
      "Time required f/ boostrap rep  89 of 100: 6.180298089981079\n",
      "Time required f/ boostrap rep  90 of 100: 20.303452253341675\n",
      "Time required f/ boostrap rep  91 of 100: 55.9804527759552\n",
      "Time required f/ boostrap rep  92 of 100: 110.18473386764526\n",
      "Time required f/ boostrap rep  93 of 100: 6.99859619140625\n",
      "Time required f/ boostrap rep  94 of 100: 86.81321501731873\n",
      "Time required f/ boostrap rep  95 of 100: 4.9217369556427\n",
      "Time required f/ boostrap rep  96 of 100: 54.51372790336609\n",
      "Time required f/ boostrap rep  97 of 100: 2.8502938747406006\n",
      "Time required f/ boostrap rep  98 of 100: 6.062314987182617\n",
      "Time required f/ boostrap rep  99 of 100: 3.951864004135132\n",
      "Time required f/ boostrap rep  100 of 100: 65.17612910270691\n"
     ]
    }
   ],
   "source": [
    "[Bootstrap_Results, var_LATE, vcov_strata_shares, vcov_theta] = bsLATE_mle(theta_em, X, Z, cLATE=False, \\\n",
    "                                                                           nocons=True, s_wgt=sw, silent=False, B=100, \\\n",
    "                                                                           gtol=1e-2, xtol=1e-4, maxiter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrap standard errors suggest that the model-based LATE estimate is also rather imprecisely estimated. In contrast the compliance strata shares are precisely determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "- Model-based IV estimates                                                 -\n",
      "----------------------------------------------------------------------------\n",
      "Number of observations      n : 1,480          \n",
      "Outcome,                    Y : lwage76\n",
      "Treatment (binary),         D : ed76\n",
      "Instrument (binary),        Z : nearc4\n",
      "(see results below for list of pre-treament control variables)\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "- Multinomial logit model for conditional compliance strata membership     -\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "          compliers    s.e.  always-takers    s.e.\n",
      "age76        0.0098  0.0124         0.0090  0.0084\n",
      "smsa66r      0.1248  0.2592        -0.3526  0.1866\n",
      "constant    -1.7815  0.4011        -0.8213  0.2222\n",
      "\n",
      "Estimated compliance strata population shares:\n",
      "----------------------------------------------\n",
      "\n",
      "                share    s.e.\n",
      "never-takers   0.5959  0.0002\n",
      "compliers      0.1444  0.0010\n",
      "always-takers  0.2597  0.0008\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "- Gaussian models for potential outcome distributions                      -\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "          Y(0): never-takers    s.e.  Y(0): compliers    s.e.  \\\n",
      "age76                 0.0403  0.0041          -0.0061  0.0500   \n",
      "smsa66r               0.1142  0.0372           0.2945  0.4091   \n",
      "constant              5.1523  0.1170           6.2152  1.4590   \n",
      "sigma                 0.3604  0.0099           0.4904  0.1474   \n",
      "\n",
      "          Y(1): compliers    s.e.  Y(1): always-takers    s.e.  \n",
      "age76              0.0893  0.0210               0.0568  0.0071  \n",
      "smsa66r           -0.3336  0.2475               0.1970  0.0476  \n",
      "constant           4.0685  0.6423               4.7774  0.2023  \n",
      "sigma              0.4561  0.0618               0.2981  0.0160  \n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "- Model-based Local Average Treatement Effect Estimate                     -\n",
      "----------------------------------------------------------------------------\n",
      "LATE  :      0.0888\n",
      "s.e.  : (    0.2428)\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "display_LATE_mle(theta_em, vcov_theta, LATE_em, var_LATE, strata_shares_em, vcov_strata_shares, \\\n",
    "                 D, Y, Z, X, cLATE=False, nocons=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
